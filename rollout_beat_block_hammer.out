Wed Feb  4 17:43:46 2026       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 570.158.01             Driver Version: 570.158.01     CUDA Version: 12.8     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA H800                    On  |   00000000:9D:00.0 Off |                    0 |
| N/A   22C    P0             69W /  700W |       0MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA H800                    On  |   00000000:C3:00.0 Off |                    0 |
| N/A   21C    P0             70W /  700W |       0MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA H800                    On  |   00000000:D1:00.0 Off |                    0 |
| N/A   22C    P0             65W /  700W |       0MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA H800                    On  |   00000000:DF:00.0 Off |                    0 |
| N/A   23C    P0             69W /  700W |       0MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
/cm/local/apps/slurm/var/spool/job343976/slurm_script: line 22: /home/congcong/miniconda3/bin/activate: Permission denied
[33mgpu id (to use): 0,1,2,3[0m
[32mRender Well[0m
{'policy_name': 'openpi_test', 'task_name': None, 'task_config': 'demo_clean', 'ckpt_setting': 'robotwin_aloha_lerobot', 'seed': 0, 'instruction_type': 'unseen', 'train_config_name': 'pi0_base_aloha_robotwin_full_torch', 'model_name': 'robotwin_aloha_lerobot', 'checkpoint_id': 145000, 'pi0_step': 8, 'device': 'cuda:0'}
Task names: ['beat_block_hammer', 'demo_clean', 'pi0_base_aloha_robotwin_full_torch', 'robotwin_aloha_lerobot', '0', '0,1,2,3', 'rollout_1.pkl', '100000', '100001', '100002', '100003']
Env seed: [100000]
Processing task: beat_block_hammer
###########################Start Evaluation###########################
start process in gpu:  0
start process in gpu:  1
start process in gpu:  2
start process in gpu:  3
start process in gpu:  4
start process in gpu:  5
start process in gpu:  6
start process in gpu:  7
Task 0 (GPU 0) output:
Process 3458962: CUDA_VISIBLE_DEVICES = 0
Process 3458962: CUDA available: True
Process 3458962: Device count: 1
Process 3458962: Current device: 0
Process 3458962: Device name: NVIDIA H800

Task 0 errors:
Traceback (most recent call last):
  File "<string>", line 31, in <module>
ModuleNotFoundError: No module named 'script.RobotwinEnvWrapper'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<string>", line 80, in <module>
NameError: name 'task_id' is not defined

Task 1 (GPU 1) output:
Process 3458963: CUDA_VISIBLE_DEVICES = 1
Process 3458963: CUDA available: True
Process 3458963: Device count: 1
Process 3458963: Current device: 0
Process 3458963: Device name: NVIDIA H800

Task 1 errors:
Traceback (most recent call last):
  File "<string>", line 31, in <module>
ModuleNotFoundError: No module named 'script.RobotwinEnvWrapper'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<string>", line 80, in <module>
NameError: name 'task_id' is not defined

Task 2 (GPU 2) output:
Process 3458964: CUDA_VISIBLE_DEVICES = 2
Process 3458964: CUDA available: True
Process 3458964: Device count: 1
Process 3458964: Current device: 0
Process 3458964: Device name: NVIDIA H800

Task 2 errors:
Traceback (most recent call last):
  File "<string>", line 31, in <module>
ModuleNotFoundError: No module named 'script.RobotwinEnvWrapper'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<string>", line 80, in <module>
NameError: name 'task_id' is not defined

Task 3 (GPU 3) output:
Process 3458965: CUDA_VISIBLE_DEVICES = 3
Process 3458965: CUDA available: True
Process 3458965: Device count: 1
Process 3458965: Current device: 0
Process 3458965: Device name: NVIDIA H800

Task 3 errors:
Traceback (most recent call last):
  File "<string>", line 31, in <module>
ModuleNotFoundError: No module named 'script.RobotwinEnvWrapper'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<string>", line 80, in <module>
NameError: name 'task_id' is not defined

Task 4 (GPU 4) output:
Process 3458966: CUDA_VISIBLE_DEVICES = 4
Process 3458966: CUDA available: False
Process 3458966: Device count: 0

Task 4 errors:
Traceback (most recent call last):
  File "<string>", line 31, in <module>
ModuleNotFoundError: No module named 'script.RobotwinEnvWrapper'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<string>", line 80, in <module>
NameError: name 'task_id' is not defined

Task 5 (GPU 5) output:
Process 3458967: CUDA_VISIBLE_DEVICES = 5
Process 3458967: CUDA available: False
Process 3458967: Device count: 0

Task 5 errors:
Traceback (most recent call last):
  File "<string>", line 31, in <module>
ModuleNotFoundError: No module named 'script.RobotwinEnvWrapper'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<string>", line 80, in <module>
NameError: name 'task_id' is not defined

Task 6 (GPU 6) output:
Process 3458968: CUDA_VISIBLE_DEVICES = 6
Process 3458968: CUDA available: False
Process 3458968: Device count: 0

Task 6 errors:
Traceback (most recent call last):
  File "<string>", line 31, in <module>
ModuleNotFoundError: No module named 'script.RobotwinEnvWrapper'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<string>", line 80, in <module>
NameError: name 'task_id' is not defined

Task 7 (GPU 7) output:
Process 3458969: CUDA_VISIBLE_DEVICES = 7
Process 3458969: CUDA available: False
Process 3458969: Device count: 0

Task 7 errors:
Traceback (most recent call last):
  File "<string>", line 31, in <module>
ModuleNotFoundError: No module named 'script.RobotwinEnvWrapper'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<string>", line 80, in <module>
NameError: name 'task_id' is not defined

Process 3458149: Error in task 0: [Errno 2] No such file or directory: '/project/peilab/wzj/RoboTwin/tmp/2026-02-04 17:44:11_gpu_0_result.pkl'
Process 3458149: Error in task 1: [Errno 2] No such file or directory: '/project/peilab/wzj/RoboTwin/tmp/2026-02-04 17:44:11_gpu_1_result.pkl'
Process 3458149: Error in task 2: [Errno 2] No such file or directory: '/project/peilab/wzj/RoboTwin/tmp/2026-02-04 17:44:11_gpu_2_result.pkl'
Process 3458149: Error in task 3: [Errno 2] No such file or directory: '/project/peilab/wzj/RoboTwin/tmp/2026-02-04 17:44:11_gpu_3_result.pkl'
Process 3458149: Error in task 4: [Errno 2] No such file or directory: '/project/peilab/wzj/RoboTwin/tmp/2026-02-04 17:44:11_gpu_4_result.pkl'
Process 3458149: Error in task 5: [Errno 2] No such file or directory: '/project/peilab/wzj/RoboTwin/tmp/2026-02-04 17:44:11_gpu_5_result.pkl'
Process 3458149: Error in task 6: [Errno 2] No such file or directory: '/project/peilab/wzj/RoboTwin/tmp/2026-02-04 17:44:11_gpu_6_result.pkl'
Process 3458149: Error in task 7: [Errno 2] No such file or directory: '/project/peilab/wzj/RoboTwin/tmp/2026-02-04 17:44:11_gpu_7_result.pkl'
Total time: 8.817594051361084
Length of results: 0
Traceback (most recent call last):
  File "/project/peilab/wzj/RoboTwin/script/distributed_loop_collect_fm_wzj.py", line 258, in <module>
    run_sapien_distributed_subprocess(usr_args, 8, 16, env_seed=env_seed, file_name=file_name)
  File "/project/peilab/wzj/RoboTwin/script/distributed_loop_collect_fm_wzj.py", line 229, in run_sapien_distributed_subprocess
    print(f"Success rate: {sum(all_results)/len(all_results)*100:.1f}%")
                           ~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~
ZeroDivisionError: division by zero
[33mgpu id (to use): 0,1,2,3[0m
[32mRender Well[0m
{'policy_name': 'openpi_test', 'task_name': None, 'task_config': 'demo_clean', 'ckpt_setting': 'robotwin_aloha_lerobot', 'seed': 0, 'instruction_type': 'unseen', 'train_config_name': 'pi0_base_aloha_robotwin_full_torch', 'model_name': 'robotwin_aloha_lerobot', 'checkpoint_id': 145000, 'pi0_step': 8, 'device': 'cuda:0'}
Task names: ['beat_block_hammer', 'demo_clean', 'pi0_base_aloha_robotwin_full_torch', 'robotwin_aloha_lerobot', '0', '0,1,2,3', 'rollout_2.pkl', '100004', '100005', '100006', '100007']
Env seed: [100004]
Processing task: beat_block_hammer
###########################Start Evaluation###########################
start process in gpu:  0
start process in gpu:  1
start process in gpu:  2
start process in gpu:  3
start process in gpu:  4
start process in gpu:  5
start process in gpu:  6
start process in gpu:  7
Task 0 (GPU 0) output:
Process 3460341: CUDA_VISIBLE_DEVICES = 0
Process 3460341: CUDA available: True
Process 3460341: Device count: 1
Process 3460341: Current device: 0
Process 3460341: Device name: NVIDIA H800

Task 0 errors:
Traceback (most recent call last):
  File "<string>", line 31, in <module>
ModuleNotFoundError: No module named 'script.RobotwinEnvWrapper'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<string>", line 80, in <module>
NameError: name 'task_id' is not defined

Task 1 (GPU 1) output:
Process 3460343: CUDA_VISIBLE_DEVICES = 1
Process 3460343: CUDA available: True
Process 3460343: Device count: 1
Process 3460343: Current device: 0
Process 3460343: Device name: NVIDIA H800

Task 1 errors:
Traceback (most recent call last):
  File "<string>", line 31, in <module>
ModuleNotFoundError: No module named 'script.RobotwinEnvWrapper'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<string>", line 80, in <module>
NameError: name 'task_id' is not defined

Task 2 (GPU 2) output:
Process 3460344: CUDA_VISIBLE_DEVICES = 2
Process 3460344: CUDA available: True
Process 3460344: Device count: 1
Process 3460344: Current device: 0
Process 3460344: Device name: NVIDIA H800

Task 2 errors:
Traceback (most recent call last):
  File "<string>", line 31, in <module>
ModuleNotFoundError: No module named 'script.RobotwinEnvWrapper'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<string>", line 80, in <module>
NameError: name 'task_id' is not defined

Task 3 (GPU 3) output:
Process 3460345: CUDA_VISIBLE_DEVICES = 3
Process 3460345: CUDA available: True
Process 3460345: Device count: 1
Process 3460345: Current device: 0
Process 3460345: Device name: NVIDIA H800

Task 3 errors:
Traceback (most recent call last):
  File "<string>", line 31, in <module>
ModuleNotFoundError: No module named 'script.RobotwinEnvWrapper'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<string>", line 80, in <module>
NameError: name 'task_id' is not defined

Task 4 (GPU 4) output:
Process 3460346: CUDA_VISIBLE_DEVICES = 4
Process 3460346: CUDA available: False
Process 3460346: Device count: 0

Task 4 errors:
Traceback (most recent call last):
  File "<string>", line 31, in <module>
ModuleNotFoundError: No module named 'script.RobotwinEnvWrapper'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<string>", line 80, in <module>
NameError: name 'task_id' is not defined

Task 5 (GPU 5) output:
Process 3460347: CUDA_VISIBLE_DEVICES = 5
Process 3460347: CUDA available: False
Process 3460347: Device count: 0

Task 5 errors:
Traceback (most recent call last):
  File "<string>", line 31, in <module>
ModuleNotFoundError: No module named 'script.RobotwinEnvWrapper'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<string>", line 80, in <module>
NameError: name 'task_id' is not defined

Task 6 (GPU 6) output:
Process 3460348: CUDA_VISIBLE_DEVICES = 6
Process 3460348: CUDA available: False
Process 3460348: Device count: 0

Task 6 errors:
Traceback (most recent call last):
  File "<string>", line 31, in <module>
ModuleNotFoundError: No module named 'script.RobotwinEnvWrapper'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<string>", line 80, in <module>
NameError: name 'task_id' is not defined

Task 7 (GPU 7) output:
Process 3460349: CUDA_VISIBLE_DEVICES = 7
Process 3460349: CUDA available: False
Process 3460349: Device count: 0

Task 7 errors:
Traceback (most recent call last):
  File "<string>", line 31, in <module>
ModuleNotFoundError: No module named 'script.RobotwinEnvWrapper'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<string>", line 80, in <module>
NameError: name 'task_id' is not defined

Process 3459783: Error in task 0: [Errno 2] No such file or directory: '/project/peilab/wzj/RoboTwin/tmp/2026-02-04 17:44:32_gpu_0_result.pkl'
Process 3459783: Error in task 1: [Errno 2] No such file or directory: '/project/peilab/wzj/RoboTwin/tmp/2026-02-04 17:44:32_gpu_1_result.pkl'
Process 3459783: Error in task 2: [Errno 2] No such file or directory: '/project/peilab/wzj/RoboTwin/tmp/2026-02-04 17:44:32_gpu_2_result.pkl'
Process 3459783: Error in task 3: [Errno 2] No such file or directory: '/project/peilab/wzj/RoboTwin/tmp/2026-02-04 17:44:32_gpu_3_result.pkl'
Process 3459783: Error in task 4: [Errno 2] No such file or directory: '/project/peilab/wzj/RoboTwin/tmp/2026-02-04 17:44:32_gpu_4_result.pkl'
Process 3459783: Error in task 5: [Errno 2] No such file or directory: '/project/peilab/wzj/RoboTwin/tmp/2026-02-04 17:44:32_gpu_5_result.pkl'
Process 3459783: Error in task 6: [Errno 2] No such file or directory: '/project/peilab/wzj/RoboTwin/tmp/2026-02-04 17:44:32_gpu_6_result.pkl'
Process 3459783: Error in task 7: [Errno 2] No such file or directory: '/project/peilab/wzj/RoboTwin/tmp/2026-02-04 17:44:32_gpu_7_result.pkl'
Total time: 4.043558120727539
Length of results: 0
Traceback (most recent call last):
  File "/project/peilab/wzj/RoboTwin/script/distributed_loop_collect_fm_wzj.py", line 258, in <module>
    run_sapien_distributed_subprocess(usr_args, 8, 16, env_seed=env_seed, file_name=file_name)
  File "/project/peilab/wzj/RoboTwin/script/distributed_loop_collect_fm_wzj.py", line 229, in run_sapien_distributed_subprocess
    print(f"Success rate: {sum(all_results)/len(all_results)*100:.1f}%")
                           ~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~
ZeroDivisionError: division by zero
Wed Feb  4 18:02:49 2026       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 570.158.01             Driver Version: 570.158.01     CUDA Version: 12.8     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA H800                    On  |   00000000:9D:00.0 Off |                    0 |
| N/A   22C    P0             69W /  700W |       0MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA H800                    On  |   00000000:C3:00.0 Off |                    0 |
| N/A   21C    P0             70W /  700W |       0MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA H800                    On  |   00000000:D1:00.0 Off |                    0 |
| N/A   22C    P0             65W /  700W |       0MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA H800                    On  |   00000000:DF:00.0 Off |                    0 |
| N/A   23C    P0             69W /  700W |       0MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
/cm/local/apps/slurm/var/spool/job343981/slurm_script: line 22: /home/congcong/miniconda3/bin/activate: Permission denied
[33mgpu id (to use): 0,1,2,3[0m
[32mRender Well[0m
{'policy_name': 'openpi_test', 'task_name': None, 'task_config': 'demo_clean', 'ckpt_setting': 'robotwin_aloha_lerobot', 'seed': 0, 'instruction_type': 'unseen', 'train_config_name': 'pi0_base_aloha_robotwin_full_torch', 'model_name': 'robotwin_aloha_lerobot', 'checkpoint_id': 145000, 'pi0_step': 8, 'device': 'cuda:0'}
Task names: ['beat_block_hammer']
Env seed: [100000, 100001, 100002, 100003]
Processing task: beat_block_hammer
###########################Start Evaluation###########################
start process in gpu:  0
start process in gpu:  1
start process in gpu:  2
start process in gpu:  3
start process in gpu:  4
start process in gpu:  5
start process in gpu:  6
start process in gpu:  7
slurmstepd: error: *** JOB 343981 ON dgx-23 CANCELLED AT 2026-02-04T18:12:56 ***
Wed Feb  4 18:13:20 2026       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 570.158.01             Driver Version: 570.158.01     CUDA Version: 12.8     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA H800                    On  |   00000000:9D:00.0 Off |                    0 |
| N/A   22C    P0             70W /  700W |       0MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA H800                    On  |   00000000:C3:00.0 Off |                    0 |
| N/A   21C    P0             70W /  700W |       0MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA H800                    On  |   00000000:D1:00.0 Off |                    0 |
| N/A   23C    P0             66W /  700W |       0MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA H800                    On  |   00000000:DF:00.0 Off |                    0 |
| N/A   24C    P0             69W /  700W |       0MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
/cm/local/apps/slurm/var/spool/job343985/slurm_script: line 22: /home/congcong/miniconda3/bin/activate: Permission denied
[33mgpu id (to use): 0,1,2,3[0m
[32mRender Well[0m
usage: distributed_loop_collect_fm_wzj.py [-h] --config CONFIG
                                          [--file_name FILE_NAME] --task_names
                                          TASK_NAMES [TASK_NAMES ...]
                                          [--env_seed ENV_SEED [ENV_SEED ...]]
                                          [--gpu_num GPU_NUM]
                                          [--batch_size_per_gpu BATCH_SIZE_PER_GPU]
                                          [--overrides ...]
distributed_loop_collect_fm_wzj.py: error: argument --gpu_num: invalid int value: ''
[33mgpu id (to use): 0,1,2,3[0m
[32mRender Well[0m
usage: distributed_loop_collect_fm_wzj.py [-h] --config CONFIG
                                          [--file_name FILE_NAME] --task_names
                                          TASK_NAMES [TASK_NAMES ...]
                                          [--env_seed ENV_SEED [ENV_SEED ...]]
                                          [--gpu_num GPU_NUM]
                                          [--batch_size_per_gpu BATCH_SIZE_PER_GPU]
                                          [--overrides ...]
distributed_loop_collect_fm_wzj.py: error: argument --gpu_num: invalid int value: ''
Wed Feb  4 18:14:50 2026       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 570.158.01             Driver Version: 570.158.01     CUDA Version: 12.8     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA H800                    On  |   00000000:9D:00.0 Off |                    0 |
| N/A   22C    P0             69W /  700W |       0MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA H800                    On  |   00000000:C3:00.0 Off |                    0 |
| N/A   21C    P0             70W /  700W |       0MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA H800                    On  |   00000000:D1:00.0 Off |                    0 |
| N/A   22C    P0             65W /  700W |       0MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA H800                    On  |   00000000:DF:00.0 Off |                    0 |
| N/A   23C    P0             69W /  700W |       0MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
/cm/local/apps/slurm/var/spool/job343986/slurm_script: line 22: /home/congcong/miniconda3/bin/activate: Permission denied
[33mgpu id (to use): 0,1,2,3[0m
[32mRender Well[0m
usage: distributed_loop_collect_fm_wzj.py [-h] --config CONFIG
                                          [--file_name FILE_NAME] --task_names
                                          TASK_NAMES [TASK_NAMES ...]
                                          [--env_seed ENV_SEED [ENV_SEED ...]]
                                          [--gpu_num GPU_NUM]
                                          [--batch_size_per_gpu BATCH_SIZE_PER_GPU]
                                          [--overrides ...]
distributed_loop_collect_fm_wzj.py: error: argument --gpu_num: invalid int value: 'rollout_1.pkl'
[33mgpu id (to use): 0,1,2,3[0m
[32mRender Well[0m
usage: distributed_loop_collect_fm_wzj.py [-h] --config CONFIG
                                          [--file_name FILE_NAME] --task_names
                                          TASK_NAMES [TASK_NAMES ...]
                                          [--env_seed ENV_SEED [ENV_SEED ...]]
                                          [--gpu_num GPU_NUM]
                                          [--batch_size_per_gpu BATCH_SIZE_PER_GPU]
                                          [--overrides ...]
distributed_loop_collect_fm_wzj.py: error: argument --gpu_num: invalid int value: 'rollout_2.pkl'
Wed Feb  4 18:22:21 2026       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 570.158.01             Driver Version: 570.158.01     CUDA Version: 12.8     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA H800                    On  |   00000000:D1:00.0 Off |                    0 |
| N/A   22C    P0             65W /  700W |       0MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA H800                    On  |   00000000:DF:00.0 Off |                    0 |
| N/A   23C    P0             69W /  700W |       0MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
/cm/local/apps/slurm/var/spool/job343989/slurm_script: line 22: /home/congcong/miniconda3/bin/activate: Permission denied
[33mgpu id (to use): 0,1[0m
[32mRender Well[0m
{'policy_name': 'openpi_test', 'task_name': None, 'task_config': 'demo_clean', 'ckpt_setting': 'robotwin_aloha_lerobot', 'seed': 0, 'instruction_type': 'unseen', 'train_config_name': 'pi0_base_aloha_robotwin_full_torch', 'model_name': 'robotwin_aloha_lerobot', 'checkpoint_id': 145000, 'pi0_step': 8, 'device': 'cuda:0'}
Task names: ['beat_block_hammer']
Env seed: [100000, 100001]
GPU num: 2
Batch size per GPU: 16
Processing task: beat_block_hammer
###########################Start Evaluation###########################
start process in gpu:  0
start process in gpu:  1
